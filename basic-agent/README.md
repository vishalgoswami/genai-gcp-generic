# Google ADK Friendly Agent# Google ADK Friendly Agent



A production-ready conversational AI agent built with **Google's Agent Development Kit (ADK)**, featuring **dual-layer safety protection** (Vertex AI + Model Armor), powered by Gemini 2.0 Flash, and deployed on Vertex AI Agent Engine.A production-ready conversational AI agent built with **Google's Agent Development Kit (ADK)**, powered by Gemini 2.0 Flash and deployed on Vertex AI Agent Engine.



## ğŸš€ Quick Start## ğŸš€ Quick Start



```bash```bash

# 1. Test locally with safety# 1. Test locally

python test_safety_local.pypython test_agent.py



# 2. Deploy to Vertex AI# 2. Deploy to Vertex AI

python deploy.pypython deploy.py



# 3. Test deployed agent# 3. Test deployed agent

python test_deployed.pypython test_deployed.py

```

# 4. Compare streaming behavior

## ğŸ“‹ Featurespython test_direct_streaming.py  # Direct Gemini API (token-level)

python demo_streaming.py          # Interactive chat with deployed agent

- ğŸ¤– Built with **Google ADK** (Agent Development Kit)```

- ğŸ’ **Gemini 2.0 Flash** model via Vertex AI

- ğŸ›¡ï¸ **Dual safety system** (Vertex AI + Model Armor)## âš¡ Streaming Behavior

- ğŸ” **Application Default Credentials (ADC)** authentication

- ğŸ’¬ **Managed session persistence** (Vertex AI Memory Bank)**Important:** The deployed ADK agent uses **response-level streaming** (complete responses in single chunks), not **token-level streaming** (individual tokens).

- ğŸ” **Cloud Trace integration** for observability

- âš¡ **Auto-scaling infrastructure** on Vertex AI| Method | Chunks | Behavior |

- ğŸ“Š **Production-ready** deployment|--------|--------|----------|

| **ADK Agent Engine** | ~1 chunk | Complete response (efficient, production-ready) |

---| **Direct Gemini API** | ~50+ chunks | Token-by-token (visual typing effect) |



## ğŸ›¡ï¸ Safety & SecuritySee `test_deployed.py` vs `test_direct_streaming.py` for comparison, and `STREAMING_NOTES.md` for details.



### Dual Safety System## ğŸ“‹ Features



Choose your protection level with configurable safety modes:- ğŸ¤– Built with **Google ADK** (Agent Development Kit)

- ğŸ’ **Gemini 2.0 Flash** model via Vertex AI

#### 1. **Vertex AI Only** (Default) âœ…- ğŸ” **Application Default Credentials (ADC)** authentication

Fast, free, built-in Google safety filters- ğŸ’¬ **Managed session persistence** (Vertex AI Memory Bank)

- Hate speech, dangerous content, harassment detection- ğŸ” **Cloud Trace integration** for observability

- Sexually explicit content blocking- âš¡ **Auto-scaling infrastructure** on Vertex AI

- PII/SPII detection- ğŸ¯ **13 supported operations** (streaming, sessions, memory)

- Threshold: `BLOCK_MEDIUM_AND_ABOVE`- ï¿½ï¸ **Comprehensive safety features** (input/output scanning, PII detection)

- ï¿½ğŸ“Š **Production-ready** deployment

**Best for:** General use, fast responses, no additional setup

### ğŸ›¡ï¸ Safety & Security

#### 2. **Model Armor Only** ğŸ”’

Advanced Google Security Command Center protection**Dual safety system with configurable modes:**

- Malicious URL/link detection and blocking

- DLP (Data Loss Prevention) integration#### Safety Modes

- Prompt injection attack detection

- CSAM (Child Sexual Abuse Material) detectionChoose your protection level:

- Custom security policies via templates

1. **Vertex AI Only** (Default) - Fast, free, built-in Google safety filters

**Best for:** Advanced security requirements, enterprise compliance   - Hate speech, dangerous content, harassment detection

   - Sexually explicit content blocking

#### 3. **Both** ğŸ›¡ï¸ğŸ”’   - PII/SPII detection

Maximum protection (Vertex AI + Model Armor combined)   - Threshold: `BLOCK_MEDIUM_AND_ABOVE`

- Multi-layer defense

- Comprehensive threat coverage2. **Model Armor Only** - Advanced Google Security Command Center protection

- Dual scanning (prompt + response)   - URL/link detection and sanitization

   - DLP (Data Loss Prevention) integration

**Best for:** Maximum security, sensitive applications   - Prompt injection attack detection

   - Custom security policies

### Configuration

3. **Both** - Maximum protection (Vertex AI + Model Armor)

Set your safety mode via environment variables in `.env`:   - Combines all safety features

   - Multi-layer defense

```bash   - Comprehensive threat coverage

# Safety Mode Selection

SAFETY_MODE=vertex_ai              # Options: vertex_ai, model_armor, both**Configure via environment variables:**

```bash

# Model Armor Configuration (required for model_armor and both modes)SAFETY_MODE=vertex_ai              # Options: vertex_ai, model_armor, both

MODEL_ARMOR_PROMPT_TEMPLATE=projects/PROJECT_ID/locations/us-central1/templates/TEMPLATE_NAMEMODEL_ARMOR_PROMPT_TEMPLATE=...    # Required for Model Armor modes

MODEL_ARMOR_RESPONSE_TEMPLATE=projects/PROJECT_ID/locations/us-central1/templates/TEMPLATE_NAMEMODEL_ARMOR_RESPONSE_TEMPLATE=...  # Required for Model Armor modes

```

# Safety Behavior

SAFETY_LOGGING=true                # Enable detailed safety logging**Interactive mode selection:**

SAFETY_FAIL_OPEN=true             # Continue with Vertex AI if Model Armor fails```bash

SAFETY_AUTO_FALLBACK=true         # Auto-fallback to Vertex AI if Model Armor unavailablepython chat_with_safety.py         # Choose mode interactively

``````



### Example .env FileSee [SAFETY_INTEGRATION.md](./SAFETY_INTEGRATION.md) and [MODEL_ARMOR_ANALYSIS.md](./MODEL_ARMOR_ANALYSIS.md) for complete documentation.



```bash## ğŸ—ï¸ Architecture

# Project Configuration

PROJECT_ID=vg-pp-001```

LOCATION=us-central1â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚   agent.py          â”‚  Local Development

# Safety Configurationâ”‚   â””â”€ root_agent     â”‚  - LlmAgent with Gemini

SAFETY_MODE=vertex_aiâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MODEL_ARMOR_PROMPT_TEMPLATE=projects/vg-pp-001/locations/us-central1/templates/model-armour-template1           â”‚

MODEL_ARMOR_RESPONSE_TEMPLATE=projects/vg-pp-001/locations/us-central1/templates/model-armour-template1           â”‚ deploy.py

SAFETY_LOGGING=true           â†“

SAFETY_FAIL_OPEN=trueâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

SAFETY_AUTO_FALLBACK=trueâ”‚  Vertex AI Agent    â”‚  Production

```â”‚  Engine             â”‚  - Managed runtime

â”‚  Resource ID:       â”‚  - Auto-scaling

### Model Armor Setupâ”‚  6012881646...      â”‚  - Cloud Trace

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Model Armor is part of Google Security Command Center Premium. To enable:           â”‚

           â”‚ query

1. **Enable Security Command Center Premium**           â†“

   ```bashâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   # Contact Google Cloud sales or support to enableâ”‚  Client Apps        â”‚  Usage

   ```â”‚  test_deployed.py   â”‚  - Stream queries

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Manage sessions

2. **Create Model Armor Template**```

   ```bash

   # Via Google Cloud Console > Security Command Center > Model Armor## ğŸ“¦ What is Google ADK?

   # Or via API (requires appropriate permissions)

   ```[Google Agent Development Kit (ADK)](https://google.github.io/adk-docs/) is Google's official framework for building AI agents:



3. **Grant IAM Permissions**- **Agent Orchestration**: Compose complex multi-agent workflows

   ```bash- **Session Management**: Built-in conversation context tracking

   gcloud projects add-iam-policy-binding PROJECT_ID \- **Tool Integration**: Access to Google Cloud tools and custom functions

     --member="user:YOUR_EMAIL" \- **Deployment**: One-line deployment to Vertex AI Agent Engine

     --role="roles/modelarmor.user"- **Production Ready**: Auto-scaling, monitoring, tracing included

   ```

## ğŸ”§ Prerequisites

4. **Update .env with Template IDs**

   ```bash```bash

   MODEL_ARMOR_PROMPT_TEMPLATE=projects/PROJECT_ID/locations/LOCATION/templates/TEMPLATE_NAME# Required

   ```- Python 3.9+

- Google Cloud SDK

**Note:** Model Armor automatically falls back to Vertex AI only if:- GCP Project (vg-pp-001)

- API is unavailable (403 errors)- Vertex AI API enabled

- Templates not configured

- `SAFETY_FAIL_OPEN=true` is set (default)# Install gcloud (macOS)

brew install google-cloud-sdk

### Safety Features by Mode```



| Feature | Vertex AI | Model Armor | Both |## âš™ï¸ Setup

|---------|-----------|-------------|------|

| **Hate Speech** | âœ… | âŒ | âœ… |### 1. Authenticate

| **Dangerous Content** | âœ… | âŒ | âœ… |

| **Harassment** | âœ… | âŒ | âœ… |```bash

| **Explicit Content** | âœ… | âŒ | âœ… |# Set up Application Default Credentials

| **PII Detection** | âœ… | âœ… | âœ… |gcloud auth application-default login

| **URL Scanning** | âŒ | âœ… | âœ… |

| **Prompt Injection** | âŒ | âœ… | âœ… |# Set your GCP project

| **DLP Integration** | âŒ | âœ… | âœ… |gcloud config set project vg-pp-001

| **CSAM Detection** | âŒ | âœ… | âœ… |```

| **Cost** | Free | Premium | Premium |

| **Speed** | Fast | Fast | Slightly slower |### 2. Install Dependencies



---```bash



## ğŸ—ï¸ Architecture```bash

# Create/activate virtual environment

```cd /Users/vishal/genai/1

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”source .venv/bin/activate

â”‚   agent.py          â”‚  Local Development

â”‚   â”œâ”€ root_agent     â”‚  - LlmAgent with Gemini# Install dependencies

â”‚   â”œâ”€ SafetyConfig   â”‚  - Configurable safety modescd basic-agent

â”‚   â””â”€ ModelArmor     â”‚  - Optional advanced scanningpip install -r requirements.txt

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

           â”‚

           â”‚ deploy.py### 3. Enable APIs

           â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```bash

â”‚  Vertex AI Agent    â”‚  Productiongcloud services enable aiplatform.googleapis.com --project=vg-pp-001

â”‚  Engine             â”‚  - Managed runtime```

â”‚  â”œâ”€ Auto-scaling    â”‚  - Built-in Vertex AI safety

â”‚  â””â”€ Cloud Trace     â”‚  - Optional Model Armor## ğŸ® Local Usage

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           â”‚### Interactive Chat

           â”‚ query

           â†“```bash

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”python test_agent.py

â”‚  Client Apps        â”‚  Usage```

â”‚  â”œâ”€ test_deployed   â”‚  - Stream queries

â”‚  â”œâ”€ Streamlit UI    â”‚  - Manage sessions**Commands:**

â”‚  â””â”€ Your apps       â”‚  - Safety analysis- Chat naturally - just type and press Enter

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- `history` - View conversation history

```- `session` - View session info

- `clear` - Start fresh conversation

**Safety Flow:**- `quit` / `exit` / `bye` - End session

1. **Input** â†’ Model Armor scan (if enabled) â†’ Vertex AI safety check

2. **Agent Processing** â†’ Gemini 2.0 Flash**Example:**

3. **Output** â†’ Vertex AI safety check â†’ Model Armor scan (if enabled) â†’ User```

You: Hi! What's your name?

---Agent: Hi there! I'm friendly_agent...



## ğŸ”§ PrerequisitesYou: Tell me a fun fact about AI

Agent: Did you know that the first AI program...

```bash

# RequiredYou: quit

- Python 3.9+```

- Google Cloud SDK

- GCP Project (e.g., vg-pp-001)## ğŸš€ Deployment to Vertex AI

- Vertex AI API enabled

### Deploy Agent

# Install gcloud (macOS)

brew install google-cloud-sdk```bash

python deploy.py

# Optional (for Model Armor)```

- Security Command Center Premium

- Model Armor API accessThis will:

```1. Import `root_agent` from `agent.py`

2. Package the agent with dependencies

---3. Upload to Vertex AI Agent Engine

4. Create managed infrastructure

## âš™ï¸ Setup5. Enable Cloud Trace monitoring

6. Return resource ID

### 1. Authenticate

**Output:**

```bash```

# Set up Application Default CredentialsğŸš€ Deploying Friendly Agent to Vertex AI Agent Engine

gcloud auth application-default loginâœ“ Successfully imported root_agent

âœ“ Vertex AI initialized successfully

# Set your GCP projectâœ“ Deployment completed successfully!

gcloud config set project YOUR_PROJECT_ID

```Resource Name: projects/220428740243/locations/us-central1/reasoningEngines/6012881646632566784

```

### 2. Install Dependencies

### Current Deployment

```bash

# Create/activate virtual environment```

python3 -m venv .venvResource ID:  6012881646632566784

source .venv/bin/activate  # On macOS/LinuxProject:      vg-pp-001

# .venv\Scripts\activate   # On WindowsLocation:     us-central1

Model:        gemini-2.0-flash-exp

# Install dependenciesStatus:       âœ… Production Ready

pip install -r requirements.txtTracing:      Enabled (Cloud Trace)

``````



### 3. Enable APIs## ğŸ§ª Testing Deployed Agent



```bash### Run Tests

gcloud services enable aiplatform.googleapis.com --project=YOUR_PROJECT_ID

``````bash

python test_deployed.py

### 4. Configure Environment```



```bash**Tests:**

# Copy example environment file1. âœ… Create session

cp .env.example .env2. âœ… Stream queries (3 test queries)

3. âœ… List sessions

# Edit .env with your settings4. âœ… Get session details

# Set PROJECT_ID, LOCATION, and safety configuration5. âœ… Delete session

```

**Output:**

---```

ğŸ§ª Testing Deployed ADK Agent

## ğŸ§ª Testing======================================================================



### Local Testing (Recommended)ğŸ“¡ Connecting to deployed agent...

âœ“ Connected successfully!

Test your agent locally with comprehensive safety checks:

ğŸ”§ Supported Operations:

```bash  â€¢ async_stream_query

python test_safety_local.py  â€¢ async_create_session

```  â€¢ async_list_sessions

  â€¢ async_get_session

**What it tests:**  â€¢ async_delete_session

- âœ… Normal queries (4 tests)  â€¢ async_add_session_to_memory

- ğŸ›¡ï¸ PII/SPII detection (4 tests)  â€¢ async_search_memory

- âš ï¸ Potentially harmful requests (4 tests)  ... (13 total operations)

- ğŸš« Inappropriate content (3 tests)

- ğŸ”’ Jailbreak attempts (3 tests)âœ… Testing Complete!

- ğŸ”§ Edge cases (4 tests)```



**Sample Output:**### ğŸ›¡ï¸ Safety Feature Testing

```

ğŸ§ª LOCAL SAFETY TESTING - ADK Agent with Safety FeaturesTest the comprehensive safety filters locally before deployment:

================================================================================

Project: vg-pp-001```bash

Model: gemini-2.0-flash-exp# Test all safety categories

Safety Mode: vertex_aipython test_safety_local.py

Safety Settings: BLOCK_MEDIUM_AND_ABOVE

# Test specific categories

================================================================================python test_safety_local.py normal              # Normal queries

Test #1 - Category: NORMALpython test_safety_local.py pii_spii            # PII/SPII detection

Prompt: Hello! How are you today?python test_safety_local.py potentially_harmful # Harmful content

--------------------------------------------------------------------------------python test_safety_local.py inappropriate       # Explicit content

Response: Hi there! I'm doing great and ready to assist...python test_safety_local.py jailbreak_attempts  # Bypass attempts

```

ğŸ›¡ï¸  SAFETY ANALYSIS:

   Blocked: False**Test Categories:**

   Safety Mode: vertex_ai- âœ… **normal** (4 tests): Verify benign queries work correctly

   Finish Reason: STOP- ğŸ›¡ï¸ **pii_spii** (4 tests): PII detection (SSN, credit cards, addresses)

   - âš ï¸ **potentially_harmful** (4 tests): Dangerous requests (weapons, hacking)

âœ… PASSED- ğŸš« **inappropriate** (3 tests): Explicit/violent content

- ğŸ”’ **jailbreak_attempts** (3 tests): Safety bypass attempts

================================================================================- ğŸ”§ **edge_cases** (4 tests): Empty inputs, long text, etc.

TEST SUMMARY

================================================================================**Sample Output:**

NORMAL: 4/4 passed (100.0%)```

PII_SPII: 4/4 passed (100.0%)**Sample Output:**

```

Overall Success Rate: 100.0%ğŸ§ª LOCAL SAFETY TESTING - ADK Agent with Safety Features

```================================================================================

Project: vg-pp-001

**Test specific categories:**Model: gemini-2.0-flash-exp

```bashSafety Settings: BLOCK_MEDIUM_AND_ABOVE for all harm categories

python test_safety_local.py normal              # Normal queries only

python test_safety_local.py pii_spii            # PII detection onlyTesting categories:

python test_safety_local.py potentially_harmful # Harmful content only  - normal

```  - pii_spii



### Deployed Agent Testing================================================================================

Test #1 - Category: NORMAL

After deployment, test the production agent:```



```bash### ğŸ›¡ï¸ Safety Modes Usage

python test_deployed.py

```**Interactive chat with mode selection:**



**Tests:**```bash

1. âœ… Connection to deployed agentpython chat_with_safety.py

2. âœ… Create session```

3. âœ… Stream queries (3 test queries)

4. âœ… List sessions**Features:**

5. âœ… Get session details- Switch between safety modes on-the-fly

6. âœ… Delete session- See real-time safety analysis

- Test different protection levels

**Output:**

```**Commands:**

ğŸ§ª Testing Deployed ADK Agent```

======================================================================/mode 1     # Switch to Vertex AI only

/mode 2     # Switch to Model Armor only

ğŸ“¡ Connecting to deployed agent.../mode 3     # Switch to both (maximum protection)

Resource: projects/.../reasoningEngines/.../info       # Show current configuration

âœ“ Connected successfully!/clear      # Clear conversation history

/quit       # Exit

ğŸ”§ Supported Operations (13):```

  â€¢ async_stream_query

  â€¢ async_create_session**Example Session:**

  â€¢ async_list_sessions```

  ... and 10 moreğŸ¤– ADK Agent - Interactive Chat with Safety Modes

================================================================================

âœ… All Tests Passed!Available Safety Modes:

```  1. Vertex AI Only (Default) - Fast, free, built-in safety filters

  2. Model Armor Only - Advanced URL/DLP detection

---  3. Both - Maximum protection with Vertex AI + Model Armor

================================================================================

## ğŸš€ Deployment

You: /mode 3

### Deploy to Vertex AI Agent EngineğŸ”„ Initializing agent with mode: both...

âœ… Agent initialized successfully!

```bash   Mode: both

python deploy.py   Prompt Template: model-armor-template-1

```   Response Template: model-armor-template-1



**Deployment Process:**You: Tell me about AI safety

1. âœ… Imports `root_agent` from `agent.py`ğŸ¤– Agent: AI safety is crucial for responsible development...

2. âœ… Packages agent with dependencies

3. âœ… Uploads to Vertex AI Agent EngineYou: /info

4. âœ… Creates managed infrastructureCURRENT CONFIGURATION

5. âœ… Enables Cloud Trace monitoring================================================================================

6. âœ… Returns resource IDProject: vg-pp-001

Safety Mode: both

**Output:**

```Safety Configuration:

ğŸš€ Deploying Friendly Agent to Vertex AI Agent Engine  Vertex AI: âœ“ Enabled

âœ“ Successfully imported root_agent  Model Armor: âœ“ Enabled

âœ“ Vertex AI initialized successfully  Fail Open: âœ“ Yes

âœ“ Deployment started...================================================================================

âœ“ Deployment completed successfully!```



Resource Name: projects/220428740243/locations/us-central1/reasoningEngines/6012881646632566784**Environment Configuration:**



Save this resource ID to deployed_agent_resource.txt```bash

```# .env file

SAFETY_MODE=both                              # vertex_ai, model_armor, or both

### Current Deployment StatusMODEL_ARMOR_PROMPT_TEMPLATE=template-id-1     # Model Armor template for prompts

MODEL_ARMOR_RESPONSE_TEMPLATE=template-id-2   # Model Armor template for responses

```SAFETY_LOGGING=true                           # Enable safety event logging

Resource ID:  6012881646632566784SAFETY_FAIL_OPEN=true                         # Continue on Model Armor API errors

Project:      vg-pp-001```

Location:     us-central1================================================================================

Model:        gemini-2.0-flash-expPrompt: Hello! How are you today?

Status:       âœ… Production Ready--------------------------------------------------------------------------------

Safety:       Vertex AI (built-in)Response: Hi there! I'm doing great and ready to assist...

Tracing:      Enabled (Cloud Trace)

```ğŸ›¡ï¸  SAFETY ANALYSIS:

   Blocked: False

---   Prompt Blocked: False

   Response Blocked: False

## ğŸ’» Using the Agent   Finish Reason: FinishReason.STOP



### In Python Code================================================================================

TEST SUMMARY

```python================================================================================

import asyncioNORMAL:

from agent import FriendlyAgentRunner   Total tests: 4

   Blocked: 0 (0.0%)

async def main():   Success rate: 100.0%

    # Create agent with default safety (Vertex AI)

    runner = FriendlyAgentRunner()PII_SPII:

       Total tests: 4

    # Initialize   Blocked: 0 (0.0%)

    if await runner.initialize():   Model refused PII: 100%

        print(f"âœ… Agent ready!")```

        print(f"Safety mode: {runner.safety_config.mode.get_short_name()}")

        **Expected Behavior:**

        # Send message- âœ… Normal queries: No blocking, helpful responses

        response, safety_info = await runner.send_message(- ğŸ›¡ï¸ PII data: Model refuses to process/store PII

            "Tell me about AI safety"- âš ï¸ Harmful requests: Model refuses dangerous instructions

        )- ğŸš« Explicit content: Blocks if high severity detected

        - ğŸ”’ Jailbreak: Blocked at input stage

        print(f"Response: {response}")

        print(f"Blocked: {safety_info.is_blocked}")See `SAFETY_INTEGRATION.md` for complete documentation.

        print(f"Safety ratings: {len(safety_info.safety_ratings)}")

## ğŸ’» Using Deployed Agent in Your Code

asyncio.run(main())

```### Basic Query



### With Custom Safety Mode```python

import vertexai

```pythonfrom vertexai import agent_engines

from agent import FriendlyAgentRunnerimport asyncio

from safety_config import SafetyConfig, SafetyMode

async def chat():

async def main():    # Initialize

    # Create custom safety config    vertexai.init(project="vg-pp-001", location="us-central1")

    config = SafetyConfig(    

        mode=SafetyMode.BOTH,  # Use both Vertex AI + Model Armor    # Get deployed agent

        model_armor_prompt_template="projects/.../templates/...",    agent = agent_engines.get(

        model_armor_response_template="projects/.../templates/...",        "projects/220428740243/locations/us-central1/reasoningEngines/6012881646632566784"

        enable_logging=True,    )

        fail_open=True    

    )    # Stream query

        async for chunk in agent.async_stream_query(

    # Create agent with custom config        message="Hello! How are you?",

    runner = FriendlyAgentRunner(safety_config=config)        user_id="user123",

        ):

    if await runner.initialize():        content = chunk.get("content", {})

        print(f"Safety mode: {config.mode}")        for part in content.get("parts", []):

        print(f"Model Armor available: {runner.model_armor_available}")            if "text" in part:

                        print(part["text"], end="", flush=True)

        response, safety_info = await runner.send_message("Hello!")    print()

        print(f"Response: {response}")

asyncio.run(chat())

asyncio.run(main())```

```

### With Session Management

### With Deployed Agent

```python

```pythonasync def chat_with_memory():

import vertexai    vertexai.init(project="vg-pp-001", location="us-central1")

from vertexai import agent_engines    

import asyncio    agent = agent_engines.get(

        "projects/220428740243/locations/us-central1/reasoningEngines/6012881646632566784"

async def chat():    )

    # Initialize Vertex AI    

    vertexai.init(project="vg-pp-001", location="us-central1")    user_id = "user123"

        

    # Get deployed agent    # Create session

    agent = agent_engines.get(    session = await agent.async_create_session(user_id=user_id)

        "projects/220428740243/locations/us-central1/reasoningEngines/6012881646632566784"    session_id = session["id"]

    )    

        # First message

    # Create session    async for chunk in agent.async_stream_query(

    user_id = "user123"        message="My favorite color is blue",

    session = await agent.async_create_session(user_id=user_id)        user_id=user_id,

    session_id = session["id"]        session_id=session_id,

        ):

    # Stream query with session        # Process response...

    async for chunk in agent.async_stream_query(        pass

        message="Hello! How are you?",    

        user_id=user_id,    # Agent remembers context

        session_id=session_id    async for chunk in agent.async_stream_query(

    ):        message="What's my favorite color?",

        content = chunk.get("content", {})        user_id=user_id,

        for part in content.get("parts", []):        session_id=session_id,

            if "text" in part:    ):

                print(part["text"], end="", flush=True)        # Agent will respond: "Your favorite color is blue"

    print()        pass

        

    # Clean up    # Clean up

    await agent.async_delete_session(user_id=user_id, session_id=session_id)    await agent.async_delete_session(user_id=user_id, session_id=session_id)



asyncio.run(chat())asyncio.run(chat_with_memory())

``````



---## ğŸ“Š Supported Operations



## ğŸ¨ Streamlit UIThe deployed agent exposes 13 operations:



A web interface is available in `frontend/streamlit/app.py` with:### Session Management

- `async_create_session(user_id)` - Create new session

- âœ… Toggle between local agent and deployed agent- `async_list_sessions(user_id)` - List user's sessions

- âœ… Select safety mode (Vertex AI / Model Armor / Both)- `async_get_session(user_id, session_id)` - Get session details

- âœ… Real-time safety analysis display- `async_delete_session(user_id, session_id)` - Delete session

- âœ… Session management

- âœ… Chat history### Query Operations

- `async_stream_query(message, user_id, session_id)` - Stream responses

**Start the UI:**- `stream_query(message, user_id, session_id)` - Sync streaming

```bash- `streaming_agent_run_with_events(...)` - Advanced streaming

cd ../frontend/streamlit

streamlit run app.py### Memory Operations

```- `async_add_session_to_memory(user_id, session_id)` - Save to long-term memory

- `async_search_memory(user_id, query)` - Search memories

**Features:**

- **Deployed Agent Mode**: Use your production Agent Engine deployment## ğŸ› ï¸ Development Workflow

- **Local Agent Mode**: Test with local agent and custom safety settings

- **Safety Mode Selector**: Choose Vertex AI, Model Armor, or Both### 1. Develop Locally

- **Safety Info Display**: See safety ratings and block reasons in real-time```bash

# Edit agent.py

---# Test changes

python test_agent.py

## ğŸ“Š Supported Operations```



The deployed agent exposes 13 operations:### 2. Deploy to Production

```bash

### Session Management# Deploy updates

- `async_create_session(user_id)` - Create new conversation sessionpython deploy.py

- `async_list_sessions(user_id)` - List all user sessions

- `async_get_session(user_id, session_id)` - Get session details# New resource ID will be generated

- `async_delete_session(user_id, session_id)` - Delete session# Update deployed_agent_resource.txt

```

### Query Operations

- `async_stream_query(message, user_id, session_id)` - Stream responses### 3. Test Deployed Version

- `stream_query(message, user_id, session_id)` - Sync streaming```bash

python test_deployed.py

### Memory Operations```

- `async_add_session_to_memory(user_id, session_id)` - Save to long-term memory

- `async_search_memory(user_id, query)` - Search conversation memories### 4. Monitor

```bash

---# View traces

https://console.cloud.google.com/traces/list?project=vg-pp-001

## ğŸ”§ Customization

# View logs

### Change Modelgcloud logging read 'resource.type=aiplatform.googleapis.com/ReasoningEngine' \

  --limit=50 --project=vg-pp-001

Edit `agent.py`:```

```python

root_agent = LlmAgent(## ğŸ”§ Customization

    model="gemini-2.5-flash",  # Change model version

    name="friendly_agent",### Change Model

    instruction="Your custom instructions...",

)Edit `agent.py`:

``````python

root_agent = LlmAgent(

### Adjust Safety Settings    model="gemini-2.5-flash",  # Change model

    name="friendly_agent",

Edit `agent.py` to change Vertex AI safety thresholds:    instruction="Your custom instructions...",

```python)

safety_settings = {```

    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,

    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,### Add Tools

    # ... adjust other categories

}```python

```from google.adk.agents import LlmAgent

from google.adk.tools import WikipediaTool

### Add Tools

root_agent = LlmAgent(

```python    model="gemini-2.0-flash-exp",

from google.adk.agents import LlmAgent    name="friendly_agent",

from google.adk.tools import WikipediaTool    tools=[WikipediaTool()],  # Add tools

)

root_agent = LlmAgent(```

    model="gemini-2.0-flash-exp",

    name="friendly_agent",### Adjust Temperature

    tools=[WikipediaTool()],  # Add tools

)```python

```from google.genai import types



---root_agent = LlmAgent(

    model="gemini-2.0-flash-exp",

## ğŸ› Troubleshooting    name="friendly_agent",

    generate_content_config=types.GenerateContentConfig(

### Authentication Errors        temperature=0.7,  # Adjust creativity (0.0 - 1.0)

```bash        top_p=0.95,

# Re-authenticate        max_output_tokens=2048,

gcloud auth application-default login    ),

)

# Verify credentials```

gcloud auth application-default print-access-token

```## ğŸ› Troubleshooting



### Model Armor 403 Errors### Authentication Errors

```bash```bash

# Check IAM permissions# Re-authenticate

gcloud projects get-iam-policy PROJECT_ID \gcloud auth application-default login

  --flatten="bindings[].members" \

  --filter="bindings.role:roles/modelarmor.*"# Verify credentials

gcloud auth application-default print-access-token

# Verify Security Command Center Premium is enabled```

# Contact Google Cloud support if needed

### Import Errors

# Agent will automatically fallback to Vertex AI if SAFETY_FAIL_OPEN=true```bash

```# Reinstall dependencies

pip install -r requirements.txt --force-reinstall

### Import Errors

```bash# Check installed packages

# Reinstall dependenciespip list | grep google

pip install -r requirements.txt --force-reinstall```



# Check installed packages### Deployment Failures

pip list | grep google```bash

```# Check logs

gcloud logging read \

### Deployment Failures  'resource.type=aiplatform.googleapis.com/ReasoningEngine AND severity>=ERROR' \

```bash  --limit=10 --project=vg-pp-001

# Check API is enabled

gcloud services list --enabled --project=PROJECT_ID | grep aiplatform# Verify APIs enabled

gcloud services list --enabled --project=vg-pp-001 | grep aiplatform

# View deployment logs

gcloud logging read \# Check staging bucket

  'resource.type=aiplatform.googleapis.com/ReasoningEngine AND severity>=ERROR' \gsutil ls gs://vg-pp-001-agent-staging

  --limit=10 --project=PROJECT_ID```

```

### Empty Responses

---- Check Cloud Logs for errors

- Verify model name is correct

## ğŸ“š Project Structure- Ensure environment variables are set

- Check tracing in Cloud Console

```

basic-agent/## ğŸ“š Resources

â”œâ”€â”€ agent.py                    # Main agent definition with safety

â”œâ”€â”€ safety_config.py            # Safety mode configuration### Official Documentation

â”œâ”€â”€ model_armor_scanner.py      # Model Armor API integration- [ADK Documentation](https://google.github.io/adk-docs/)

â”œâ”€â”€ deploy.py                   # Deployment script- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine)

â”œâ”€â”€ test_safety_local.py        # Local safety testing- [ADK Deployment Guide](https://docs.cloud.google.com/agent-builder/agent-engine/deploy)

â”œâ”€â”€ test_deployed.py            # Deployed agent testing- [Tracing Guide](https://docs.cloud.google.com/agent-builder/agent-engine/manage/tracing#adk)

â”œâ”€â”€ requirements.txt            # Python dependencies

â”œâ”€â”€ requirements-deploy.txt     # Deployment dependencies### Code Examples

â”œâ”€â”€ .env.example                # Example environment variables- [ADK Samples](https://github.com/GoogleCloudPlatform/agent-starter-pack)

â”œâ”€â”€ .env                        # Your environment variables (git-ignored)- [Vertex AI Samples](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/main/generative_ai)

â”œâ”€â”€ deployed_agent_resource.txt # Deployed agent resource ID

â””â”€â”€ README.md                   # This file### Support

```- [Google Cloud Support](https://cloud.google.com/support)

- [Stack Overflow](https://stackoverflow.com/questions/tagged/google-cloud-platform)

---- [Community Forums](https://discuss.google.dev/c/google-cloud/14/)



## ğŸ“š Resources## ğŸ“ License



### Official DocumentationThis project uses Google Cloud services and is subject to [Google Cloud Terms](https://cloud.google.com/terms).

- [Google ADK Documentation](https://google.github.io/adk-docs/)

- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine)## ğŸ¯ Next Steps

- [Model Armor (Security Command Center)](https://cloud.google.com/security-command-center/docs/model-armor)

- [Vertex AI Safety Filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes)1. **Enhance Agent**: Add tools, functions, or multi-agent workflows

2. **Production Setup**: Configure authentication, rate limiting, monitoring

### Code Examples3. **CI/CD**: Automate deployment with Cloud Build

- [ADK Samples](https://github.com/GoogleCloudPlatform/agent-starter-pack)4. **Scaling**: Adjust min/max instances for load

- [Vertex AI Samples](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/main/generative_ai)5. **Custom Domain**: Set up custom endpoints

6. **Integration**: Connect to your applications

---

---

## ğŸ“ License

**Status:** âœ… Production Ready  

This project uses Google Cloud services and is subject to [Google Cloud Terms](https://cloud.google.com/terms).**Last Updated:** November 8, 2025  

**Version:** 1.0.0

---

## ğŸ” Monitoring & Observability

## ğŸ¯ Next Steps

1. âœ… **Test locally** - Run `python test_safety_local.py`
2. âœ… **Deploy** - Run `python deploy.py`
3. âœ… **Test deployment** - Run `python test_deployed.py`
4. ğŸ”’ **Enable Model Armor** - Contact Google Cloud for SCC Premium
5. ğŸ“Š **Monitor** - Check Cloud Trace and logs
6. ğŸš€ **Integrate** - Connect to your applications

---

**Status:** âœ… Production Ready  
**Last Updated:** November 9, 2025  
**Version:** 2.0.0 (with Dual Safety System)
